{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "ea7034d8-8657-4929-812c-d732876db49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "import ultralytics\n",
    "\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.yolo.v8.detect.train import Loss\n",
    "\n",
    "import params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "db884179-0ec3-458a-a28a-b875545765f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58a5619e-d12c-47c0-b13c-31daa0190546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.78 🚀 Python-3.9.16 torch-1.13.1 CPU\n",
      "Setup complete ✅ (10 CPUs, 16.0 GB RAM, 530.5/926.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "ultralytics.checks(device='mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00dfbaf2-f373-4f74-96e2-eefa685cfc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/data/annotations/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "with open('datasets/data/annotations/val.json', 'r') as f:\n",
    "    val_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aaef11f-8c1c-4c7f-9edc-08d4751a0bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0788eb10-7e0c-4949-adcb-07a9dc5d005c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1190/1190 [00:00<00:00, 3100.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4760/4760 [00:05<00:00, 895.95it/s]\n"
     ]
    }
   ],
   "source": [
    "### Create YOLO labels\n",
    "\n",
    "def create_dataset(coco_json_file, mode='train'):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    images_data = coco_json_file['images']\n",
    "    annotations = coco_json_file['annotations']\n",
    "    \n",
    "    for image_data in tqdm(images_data):\n",
    "        image_id = image_data['id']\n",
    "        annos = [anno for anno in annotations if anno['image_id'] == image_id]\n",
    "        file_name = image_data['file_name']\n",
    "        label_file_name = file_name.split('.')[0] + '.txt'\n",
    "        label_file_path = f'datasets/data/labels/{mode}/{label_file_name}'\n",
    "        image_path = f'datasets/data/images/{mode}/{file_name}'\n",
    "        if not os.path.exists(image_path):\n",
    "            print(image_path)\n",
    "        \n",
    "        image_width = image_data['width']\n",
    "        image_height = image_data['height']\n",
    "\n",
    "        with open(label_file_path, 'w') as f:\n",
    "            for anno in annos:\n",
    "                category = anno['category_id']\n",
    "                x, y, w, h = anno['bbox']\n",
    "                x_center = x + w / 2\n",
    "                y_center = y + h / 2\n",
    "                x_center /= image_width\n",
    "                y_center /= image_height\n",
    "                w /= image_width\n",
    "                h /= image_height\n",
    "                \n",
    "                f.write(f'{int(category)} {x_center} {y_center} {w} {h}\\n')\n",
    "\n",
    "create_dataset(val_data, 'val')\n",
    "create_dataset(train_data, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "116b995d-0d1e-4dee-9a34-9fbbd0795287",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 640\n",
    "batch_size = 8\n",
    "pretrained = True\n",
    "epochs=10\n",
    "augment=True\n",
    "lr=1e-3\n",
    "warmup_epochs=1\n",
    "seed = 42\n",
    "config = dict(\n",
    "    framework='ultralytics',\n",
    "    image_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    pretrained=pretrained,\n",
    "    epochs=epochs,\n",
    "    warmup_epochs=warmup_epochs,\n",
    "    lr=lr,\n",
    "    augment=augment,\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c737a9a-ac39-4d85-950d-97eb46a499c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatt-zak\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/matthewzak/projects/fanthomnet/experiments/wandb/run-20230421_140429-e13643fi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/matt-zak/fanthom_challenge/runs/e13643fi' target=\"_blank\">misunderstood-energy-9</a></strong> to <a href='https://wandb.ai/matt-zak/fanthom_challenge' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/matt-zak/fanthom_challenge' target=\"_blank\">https://wandb.ai/matt-zak/fanthom_challenge</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/matt-zak/fanthom_challenge/runs/e13643fi' target=\"_blank\">https://wandb.ai/matt-zak/fanthom_challenge/runs/e13643fi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=params.WANDB_PROJECT, entity=params.ENTITY, job_type='training', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c224e574-ee40-4fcc-87c7-51680b82d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8m.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54e3d458-f387-4951-9d5f-f4a36e1b3a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainers = []\n",
    "def on_fit_epoch_end(trainer):\n",
    "    for metric, val in trainer.metrics.items():\n",
    "        metric = metric.replace('metrics/', '')\n",
    "        metric = ' '.join(metric.split('/'))\n",
    "        run.log({f'epoch {metric}': val}, step=trainer.epoch)\n",
    "def on_train_batch_end(trainer):\n",
    "    for metric, val in trainer.metrics.items():\n",
    "        metric = metric.replace('metrics/', '')\n",
    "        metric = ' '.join(metric.split('/'))\n",
    "        run.log({f'running {metric}': val})\n",
    "    \n",
    "model.add_callback('on_fit_epoch_end', on_fit_epoch_end)\n",
    "model.add_callback('on_train_batch_end', on_train_batch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cbe26d1-8a40-4208-a02a-860f0b5c6768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.83 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.78 🚀 Python-3.9.16 torch-1.13.1 CPU\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=./dataset.yaml, epochs=10, patience=50, batch=8, imgsz=640, save=True, save_period=-1, cache=True, device=mps, workers=0, project=None, name=test_run, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=False, seed=42, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_thickness=3, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=1, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/test_run35\n",
      "Overriding model.yaml nc=80 with nc=133\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.Conv                  [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.Conv                  [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.C2f                   [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.Conv                  [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.C2f                   [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.Conv                  [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.C2f                   [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.Conv                  [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.C2f                   [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.SPPF                  [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.C2f                   [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.C2f                   [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.Conv                  [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.C2f                   [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.Conv                  [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.C2f                   [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3852703  ultralytics.nn.modules.Detect                [133, [192, 384, 576]]        \n",
      "Model summary: 295 layers, 25933327 parameters, 25933311 gradients, 79.5 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "WARNING ⚠️ Comet installed but not initialized correctly, not logging this run. Comet.ml requires an API key. Please provide as the first argument to Experiment(api_key) or as an environment variable named COMET_API_KEY \n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/test_run35', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/matthewzak/projects/fanthomnet/experiments/datasets/data/labels/train... 4760 images, 0 backgrounds, 1 corrupt: 100%|██████████| 4760/4760 [00:06<00:00, 692.06it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/matthewzak/projects/fanthomnet/experiments/datasets/data/images/train/95065656-53c4-4474-b7ec-a8104b0f62b2.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0446      1.0257]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/matthewzak/projects/fanthomnet/experiments/datasets/data/labels/train.cache\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (3.2GB True): 100%|██████████| 4759/4759 [00:11<00:00, 432.40it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/matthewzak/projects/fanthomnet/experiments/datasets/data/labels/val... 1190 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1190/1190 [00:01<00:00, 681.70it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/matthewzak/projects/fanthomnet/experiments/datasets/data/labels/val.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.8GB True): 100%|██████████| 1190/1190 [00:03<00:00, 391.55it/s]\u001b[0m\n",
      "Plotting labels to runs/detect/test_run35/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/test_run35\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10         0G      1.613      2.152      1.213         33        640: 100%|██████████| 595/595 [1:05:40<00:00,  6.62s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 75/75 [09:11<00:00,  7.35s/it]\n",
      "                   all       1190       4561      0.554     0.0814     0.0613     0.0338\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10         0G      1.576      1.772       1.21         98        640:  61%|██████    | 362/595 [45:26<2:28:44, 38.30s/it]wandb: Network error (ConnectionError), entering retry loop.\n",
      "       2/10         0G      1.571      1.751      1.207         62        640: 100%|██████████| 595/595 [7:18:33<00:00, 44.22s/it]     \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 75/75 [2:08:12<00:00, 102.57s/it]   \n",
      "                   all       1190       4561      0.582     0.0987      0.107     0.0614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10         0G      1.533      1.607      1.183         75        640: 100%|██████████| 595/595 [1:01:24<00:00,  6.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 75/75 [08:47<00:00,  7.04s/it]\n",
      "                   all       1190       4561      0.538      0.162      0.145     0.0809\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10         0G       1.51      1.486      1.165         36        640: 100%|██████████| 595/595 [57:32<00:00,  5.80s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 75/75 [08:58<00:00,  7.18s/it]\n",
      "                   all       1190       4561       0.67      0.172      0.164     0.0929\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10         0G       1.48      1.417      1.156         40        640: 100%|██████████| 595/595 [58:55<00:00,  5.94s/it] \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 75/75 [08:50<00:00,  7.07s/it]\n",
      "                   all       1190       4561      0.644      0.188        0.2      0.119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10         0G      1.445      1.377      1.136         54        640: 100%|██████████| 595/595 [1:00:33<00:00,  6.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 75/75 [08:46<00:00,  7.03s/it]\n",
      "                   all       1190       4561       0.56      0.223      0.212      0.124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10         0G      1.429      1.303      1.125         52        640: 100%|██████████| 595/595 [1:01:38<00:00,  6.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 75/75 [09:06<00:00,  7.29s/it]\n",
      "                   all       1190       4561      0.605      0.243       0.25      0.142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10         0G      1.407      1.243      1.117         57        640: 100%|██████████| 595/595 [1:02:27<00:00,  6.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 75/75 [09:01<00:00,  7.21s/it]\n",
      "                   all       1190       4561      0.748      0.182      0.247       0.15\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10         0G      1.393      1.184      1.114         40        640: 100%|██████████| 595/595 [1:02:56<00:00,  6.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 75/75 [08:53<00:00,  7.11s/it]\n",
      "                   all       1190       4561      0.696      0.236      0.255      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10         0G      1.372      1.155      1.102         46        640: 100%|██████████| 595/595 [1:04:17<00:00,  6.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 75/75 [08:59<00:00,  7.20s/it]\n",
      "                   all       1190       4561      0.615      0.282      0.301      0.187\n",
      "\n",
      "10 epochs completed in 20.050 hours.\n",
      "Optimizer stripped from runs/detect/test_run35/weights/last.pt, 52.1MB\n",
      "Optimizer stripped from runs/detect/test_run35/weights/best.pt, 52.1MB\n",
      "\n",
      "Validating runs/detect/test_run35/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.78 🚀 Python-3.9.16 torch-1.13.1 CPU\n",
      "Model summary (fused): 218 layers, 25916767 parameters, 0 gradients, 79.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 75/75 [08:48<00:00,  7.04s/it]\n",
      "                   all       1190       4561      0.615      0.281      0.301      0.187\n",
      "Speed: 0.3ms preprocess, 442.0ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test_run35\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.train(\n",
    "    data='./dataset.yaml',\n",
    "    epochs=epochs,\n",
    "    warmup_epochs=warmup_epochs,\n",
    "    imgsz=image_size,\n",
    "    batch=batch_size,\n",
    "    augment=augment,\n",
    "    workers=0,\n",
    "    pretrained=pretrained,\n",
    "    cache=True,\n",
    "    save=True, \n",
    "    verbose=False,\n",
    "    name='test_run',\n",
    "    optimizer='AdamW',\n",
    "    lr0=lr,\n",
    "    device='mps',\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "2ccd0ef1-f29d-4614-a6c6-1c372c799fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "33fd5c58-6141-4f08-83dc-3edac8ea2f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.model.state_dict(), 'yolov8_trained.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92718771-117b-4d95-a443-4cacb7efa967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.78 🚀 Python-3.9.16 torch-1.13.1 CPU\n",
      "Model summary (fused): 218 layers, 25916767 parameters, 0 gradients, 79.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/matthewzak/projects/fanthomnet/experiments/datasets/data/labels/val.cache... 1190 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1190/1190 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.8GB True): 100%|██████████| 1190/1190 [00:03<00:00, 364.24it/s]\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 149/149 [02:20<00:00,  1.06it/s]\n",
      "                   all       1190       4561      0.615      0.281      0.301      0.187\n",
      "Speed: 0.3ms preprocess, 115.7ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/test_run36\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "val_results = model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5456176c-58d0-499a-b087-70e725a04d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_AP = val_results.box.all_ap\n",
    "AP = val_results.box.ap\n",
    "AP50 = val_results.box.ap50\n",
    "F1 = val_results.box.f1\n",
    "MAP = val_results.box.map\n",
    "MAP50 = val_results.box.map50\n",
    "MAP75 = val_results.box.map75\n",
    "MP = val_results.box.mp\n",
    "MR = val_results.box.mr\n",
    "nr_classes = val_results.box.nc\n",
    "P = val_results.box.p\n",
    "val_results.box.ap_class_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "51536dd5-1cf2-4b1e-9187-06c9b1709592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85,)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6cdf34d1-b3c1-41a0-af38-09bee771f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's only 85 out of 133 object classes observed in the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ab0ddd51-5b65-435c-b40b-0de8bebf8437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,  10,  11,  13,  14,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  32,  38,  40,  41,  42,  43,  44,  45,  46,  47,  49,  50,  52,  53,  57,  59,  61,  62,  63,  65,  66,  67,  68,  69,  73,  75,  76,  79,  80,  82,  83,  84,  85,  86,  87,  88,  91,  92,  93,  99,\n",
       "       100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 127, 129])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_results.box.ap_class_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4a0b0a15-d977-4703-b275-e9feb72e7bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = val_results.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1e1dc856-4b73-43a6-b29f-e6a220b917c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label_idx, avg_p in zip(val_results.box.ap_class_index, AP):\n",
    "    run.summary[f'{class_names[label_idx]}_avg_precision'] = avg_p\n",
    "\n",
    "for label_idx, avg_p50 in zip(val_results.box.ap_class_index, AP50):\n",
    "    run.summary[f'{class_names[label_idx]}_avg_precision50'] = avg_p50\n",
    "\n",
    "for label_idx, f1 in zip(val_results.box.ap_class_index, F1):\n",
    "    run.summary[f'{class_names[label_idx]}_f1'] = f1\n",
    "\n",
    "for label_idx, p in zip(val_results.box.ap_class_index, P):\n",
    "    run.summary[f'{class_names[label_idx]}_precision'] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "2dbe0fd5-47b7-411f-b741-eb947cf45943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('metrics/precision(B)', 0.6152105212684763), ('metrics/recall(B)', 0.2814127332609715), ('metrics/mAP50(B)', 0.3007012718597112), ('metrics/mAP50-95(B)', 0.18677930400459652), ('fitness', 0.198171500790108)])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_results.results_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a3d937fe-ab6d-4a82-abca-a250d823c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric, value in val_results.results_dict.items():\n",
    "    run.summary[metric] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7eacc412-6425-4d03-9c57-e08502119c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.summary['mAP'] = MAP\n",
    "run.summary['mAP50'] = MAP50\n",
    "run.summary['mAP75'] = MAP75\n",
    "run.summary['mP'] = MP\n",
    "run.summary['mR'] = MR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "496a60f7-711d-4ba0-a510-a8da25d49930",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = glob('datasets/data/images/val/*.png')\n",
    "images, labels = [], []\n",
    "for image_path in val_images:\n",
    "    labels_path = image_path.replace('images', 'labels').replace('.png', '.txt')\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    images.append(image)\n",
    "    height, width = image.shape[:2]\n",
    "    with open(labels_path, 'r') as f:\n",
    "        curr_labels = f.readlines()\n",
    "    processed_labels = []\n",
    "    for line in curr_labels:\n",
    "        line = line.strip().split()\n",
    "        category_id, x_c, y_c, w, h = line[0], float(line[1]), float(line[2]), float(line[3]), float(line[4])\n",
    "        x_c *= width\n",
    "        w *= width\n",
    "        y_c *= height\n",
    "        h *= height\n",
    "        # category id, x1, y1, x2, y2\n",
    "        processed_labels.append(\n",
    "            [\n",
    "                int(category_id),\n",
    "                int(x_c - w / 2 + 0.5),\n",
    "                int(y_c - h / 2 + 0.5),\n",
    "                int(x_c + w / 2 + 0.5),\n",
    "                int(y_c + h / 2 + 0.5)\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    labels.append(processed_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "824f026f-d0de-4eaf-a993-5492bcb52b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_pred = model.predict(images[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d627ba4f-dc13-4d23-a6c5-3128b618a1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ 'Boxes.boxes' is deprecated. Use 'Boxes.data' instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.yolo.engine.results.Boxes object with attributes:\n",
       "\n",
       "boxes: tensor([[5.6778e+02, 1.0019e+02, 6.0532e+02, 1.2613e+02, 2.9373e-01, 7.5000e+01],\n",
       "        [4.8712e+02, 1.0600e+02, 5.2796e+02, 1.3626e+02, 2.5055e-01, 7.5000e+01]])\n",
       "cls: tensor([75., 75.])\n",
       "conf: tensor([0.2937, 0.2506])\n",
       "data: tensor([[5.6778e+02, 1.0019e+02, 6.0532e+02, 1.2613e+02, 2.9373e-01, 7.5000e+01],\n",
       "        [4.8712e+02, 1.0600e+02, 5.2796e+02, 1.3626e+02, 2.5055e-01, 7.5000e+01]])\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: tensor([368, 720])\n",
       "shape: torch.Size([2, 6])\n",
       "xywh: tensor([[586.5499, 113.1585,  37.5368,  25.9386],\n",
       "        [507.5367, 121.1315,  40.8382,  30.2598]])\n",
       "xywhn: tensor([[0.8147, 0.3075, 0.0521, 0.0705],\n",
       "        [0.7049, 0.3292, 0.0567, 0.0822]])\n",
       "xyxy: tensor([[567.7816, 100.1892, 605.3184, 126.1278],\n",
       "        [487.1176, 106.0017, 527.9557, 136.2614]])\n",
       "xyxyn: tensor([[0.7886, 0.2723, 0.8407, 0.3427],\n",
       "        [0.6766, 0.2880, 0.7333, 0.3703]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_pred[3].boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ef52e574-4037-4aa2-a60b-4a6d05d9b4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0 568.0 100.0 605.0 126.0\n",
      "75.0 487.0 106.0 528.0 136.0\n"
     ]
    }
   ],
   "source": [
    "for l, a in zip(batch_pred[3].boxes.cls.numpy(), batch_pred[3].boxes.xyxy.numpy()):\n",
    "    print(l, *a.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5239bf9f-db3b-44f2-9815-260b1992ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_samples = len(images) if len(images) < 600 else 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "60f26742-eec9-4a07-8cc7-25e7a12c9892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [05:01<00:00,  5.02s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "pred_results = []\n",
    "for i in tqdm(range(0, max_samples, 10)):\n",
    "    curr_images = images[i:i + batch_size]\n",
    "    curr_labels = labels[i:i + batch_size]\n",
    "    curr_results = model.predict(curr_images)\n",
    "    for result in curr_results:\n",
    "        boxes = result.boxes.xyxy.numpy()\n",
    "        label_ids = result.boxes.cls.numpy()\n",
    "        confidence = result.boxes.conf.numpy()\n",
    "        processed_results = []\n",
    "        for category_id, conf, bbox in zip(label_ids, confidence, boxes):\n",
    "            processed_results.append(\n",
    "                [category_id, conf, *bbox]\n",
    "            )\n",
    "        pred_results.append(processed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "7736c72e-5b7a-4dd4-92a9-a92e8c3d5f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/data/annotations/val.json', 'r') as f:\n",
    "    val_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "6853e11e-3746-45d5-9db8-618920295d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = val_data['categories']\n",
    "id2cat = {cat['id']: cat['name'] for cat in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "67dc8a13-a727-405c-895b-6b6a454ce4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = wandb.Table(columns=['Image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "3713cec6-420b-4438-90d5-e2b5b330d04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [03:30,  2.85it/s]\n"
     ]
    }
   ],
   "source": [
    "for image, gt, pred in tqdm(zip(images[:max_samples], labels[:max_samples], pred_results)):\n",
    "    \n",
    "    curr_gt = []\n",
    "    for true_label in gt:\n",
    "        class_id, x1, y1, x2, y2 = true_label\n",
    "        curr_gt.append(\n",
    "            {\n",
    "                'position': {\n",
    "                    'minX': x1, \n",
    "                    'minY': y1,\n",
    "                    'maxX': x2,\n",
    "                    'maxY': y2\n",
    "                },\n",
    "                'domain': 'pixel',\n",
    "                'class_id': class_id,\n",
    "                'box_caption': id2cat[class_id]\n",
    "            }\n",
    "        )\n",
    "    curr_predictions = []\n",
    "    for predicted_label in pred:\n",
    "        class_id, conf, x1, y1, x2, y2 = predicted_label\n",
    "        class_id = int(class_id)\n",
    "        curr_predictions.append(\n",
    "            {\n",
    "                'position': {\n",
    "                    'minX': int(x1 + 0.5), \n",
    "                    'minY': int(y1 + 0.5),\n",
    "                    'maxX': int(x2 + 0.5),\n",
    "                    'maxY': int(y2 + 0.5)\n",
    "                },\n",
    "                'domain': 'pixel',\n",
    "                'class_id': class_id,\n",
    "                'box_caption': id2cat[class_id],\n",
    "                'scores': {'score': float(conf)}\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    for pred_label in pred:\n",
    "        pass\n",
    "    row = wandb.Image(\n",
    "        image, \n",
    "        boxes={\n",
    "            'predictions': {\n",
    "                'box_data': curr_predictions,\n",
    "                'class_labels': id2cat\n",
    "            },\n",
    "            'ground_truth': {\n",
    "                'box_data': curr_gt,\n",
    "                'class_labels': id2cat\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    table.add_data(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "dc70ee67-8190-4034-aa8d-c1abafb51b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log({'pred_table': table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "47e98448-0ce6-43bb-a0c9-3fc142f0084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "657b1abc-a624-459f-8e06-2b41853cd5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(file_name)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f3df1e2f-89d7-4a87-9b26-482523dbebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for detected_object in pred:\n",
    "    detected_object = detected_object.boxes  # Boxes object for bbox outputs\n",
    "    category_id = detected_object.cls\n",
    "    confidence = detected_object.conf\n",
    "    x1, y1, x2, y2 = detected_object.xyxy.cpu().numpy()[0].astype(int)\n",
    "    \n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "dbc881c3-9f24-4ec4-8cf1-6f759f1f7e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ea51f727774cc5b393d03faef67437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016743429166672284, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: /var/folders/y6/hrf78r2d3pn5xzgwhhlhb0fm0000gn/T/ipykernel_14090/2854979015.py 1 <module>\n"
     ]
    },
    {
     "ename": "CommError",
     "evalue": "Run initialization has timed out after 60.0 sec. \nPlease refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[255], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWANDB_PROJECT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mENTITY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogging_baseline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSettings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfork\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py:1164\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1163\u001b[0m         logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[0;32m-> 1164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m logger\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py:1145\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1143\u001b[0m except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1145\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1146\u001b[0m     except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/wandb/sdk/wandb_init.py:764\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m         backend\u001b[38;5;241m.\u001b[39mcleanup()\n\u001b[1;32m    763\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mteardown()\n\u001b[0;32m--> 764\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m run_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m run_result\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mCommError\u001b[0m: Run initialization has timed out after 60.0 sec. \nPlease refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-"
     ]
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project=params.WANDB_PROJECT,\n",
    "    entity=params.ENTITY,\n",
    "    job_type='logging_baseline',\n",
    "    config=config,\n",
    "    settings=wandb.Settings(start_method=\"fork\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "d226f424-6dbb-48a2-940e-5fb1506aeb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = dict()\n",
    "for label_idx, avg_p in zip(val_results.box.ap_class_index, AP):\n",
    "    metrics_dict[f'{class_names[label_idx]}_avg_precision'] = avg_p\n",
    "\n",
    "for label_idx, avg_p50 in zip(val_results.box.ap_class_index, AP50):\n",
    "    metrics_dict[f'{class_names[label_idx]}_avg_precision50'] = avg_p50\n",
    "\n",
    "for label_idx, f1 in zip(val_results.box.ap_class_index, F1):\n",
    "    metrics_dict[f'{class_names[label_idx]}_f1'] = f1\n",
    "\n",
    "for label_idx, p in zip(val_results.box.ap_class_index, P):\n",
    "    metrics_dict[f'{class_names[label_idx]}_precision'] = p\n",
    "    \n",
    "for metric, value in val_results.results_dict.items():\n",
    "    metrics_dict[metric] = value\n",
    "\n",
    "metrics_dict['mAP'] = MAP\n",
    "metrics_dict['mAP50'] = MAP50\n",
    "metrics_dict['mAP75'] = MAP75\n",
    "metrics_dict['mP'] = MP\n",
    "metrics_dict['mR'] = MR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "2a1f4c20-2a50-4385-9f2c-fe05138b2e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metrics.json', 'w') as f:\n",
    "    json.dump(metrics_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
